{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOGOMOL Neural Network\n",
    "\n",
    "This notebook was created to test the conception of BOGOMOL Convolution Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from torchsummary import summary\n",
    "\n",
    "import data.transformations as tfms\n",
    "from data.datasets import CifarDataset\n",
    "from bogomol.models import ImageClassifier\n",
    "from utils.train_steps import training_step, validation_step\n",
    "from utils.optimizer import configure_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying CUDA if possible and setting multiprocessing start method to 'spawn', instead of 'fork', as it works better on UNIX-systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-train on tiny-imagenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('uoft-cs/cifar10', cache_dir='./.datasets')\n",
    "train_set = dataset['train']\n",
    "val_set = dataset['test']\n",
    "num_classes = len(train_set.features['label'].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "train_transforms = tfms.train_transform((IMG_SIZE, IMG_SIZE), tfms.CIFAR_MEAN, tfms.CIFAR_STD)\n",
    "val_transforms = tfms.val_transform((IMG_SIZE, IMG_SIZE), tfms.CIFAR_MEAN, tfms.CIFAR_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CifarDataset(train_set, train_transforms)\n",
    "val_ds = CifarDataset(val_set, val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating simple dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "cutmix_or_mixup = tfms.cutmix_or_mixup(num_classes)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image, label in batch:\n",
    "        image = torch.Tensor(image)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    images = torch.stack(images, dim=0).float()\n",
    "    labels = torch.Tensor(labels).long()\n",
    "    return images, labels\n",
    "\n",
    "def train_collate_fn(batch):\n",
    "    return cutmix_or_mixup(collate_fn(batch))\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, collate_fn=train_collate_fn, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=8)\n",
    "val_dataloader = DataLoader(val_ds, collate_fn=collate_fn, batch_size=BATCH_SIZE, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying Image Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = 64\n",
    "model = ImageClassifier(3, entities, num_classes, 4, 5, (IMG_SIZE, IMG_SIZE)).to(device)\n",
    "model_architecture = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "model_name = f\"bogomol-{num_parameters/1e+6:.1f}M({entities})\"\n",
    "\n",
    "print(model_name)\n",
    "summary(model, (3, IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "optimizer, scheduler = configure_optimizer(model, base_lr=3e-4, weight_decay=0.05, warmup_epochs=5, total_epochs=EPOCHS, steps_per_epoch=len(train_dataloader), num_cycles=3)\n",
    "scaler = torch.GradScaler(device)\n",
    "checkpoint_pth = './models'\n",
    "best_val_loss = float('inf')\n",
    "history = {\n",
    "    \"train_loss\" : [float('inf')],\n",
    "    \"train_acc\" : [0],\n",
    "    \"val_loss\" : [float('inf')],\n",
    "    \"val_acc\" : [0]\n",
    "}\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    print(f\"Training epoch: {i+1}/{EPOCHS}\")\n",
    "    train_loss, train_acc = training_step(model, train_dataloader, optimizer, scheduler, scaler, history, accumulation_steps=4)\n",
    "    print(f\"Average training loss: {train_loss:.3f}, accuracy: {train_acc:.3f}\")\n",
    "    print(f\"Learning rate: {scheduler.get_last_lr()[0]}, gradient scale: {scaler.get_scale()}\")\n",
    "    val_loss, val_acc = validation_step(model, val_dataloader, history)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_params = model.state_dict()\n",
    "        torch.save(best_params, os.path.join(checkpoint_pth, model_name+'(cifar).pth'))\n",
    "    print(f\"Average validation loss: {val_loss:.3f}, accuracy: {val_acc:.3f}\")\n",
    "    print(\"-\"*80)\n",
    "    if train_loss is torch.nan:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_pth = './plots'\n",
    "\n",
    "plt.plot(history['train_loss'], label=\"Train loss\")\n",
    "plt.plot(history['val_loss'], label=\"Validation loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(f\"Model loss ({model_name})\")\n",
    "plt.savefig(os.path.join(plots_pth, f'{model_name}-loss(cifar10).png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['val_acc'], label=\"Validation accuracy\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(f\"Model accuracy({model_name})\")\n",
    "plt.savefig(os.path.join(plots_pth, f'{model_name}-acc(cifar10).png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./reports/{model_name}(cifar10).txt', 'w') as f:\n",
    "    f.write(f\"Train accuracy : {max(history['train_acc'])}, loss : {min(history['train_loss'])}\\n\")\n",
    "    f.write(f\"Validation accuracy : {max(history['val_acc'])}, loss : {min(history['val_loss'])}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
