{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOGOMOL Neural Network\n",
    "\n",
    "This notebook was created to test the conception of BOGOMOL Convolution Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torchvision.transforms import v2\n",
    "from datasets import load_dataset\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from src.models import ImageClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying CUDA if possible and setting multiprocessing start method to 'spawn', instead of 'fork', as it works better on UNIX-systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#torch._dynamo.config.suppress_errors = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cifar_ds = load_dataset('uoft-cs/cifar10')\n",
    "cifar_ds = load_dataset(\"flwrlabs/cinic10\")\n",
    "cifar_train = cifar_ds['train']\n",
    "cifar_val = cifar_ds['validation']\n",
    "cifar_test = cifar_ds['test']\n",
    "class_names = cifar_train.features['label'].names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    sample = cifar_train[i]\n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "    print(label)\n",
    "    fig, ax = plt.subplots()\n",
    "    print(class_names[label])\n",
    "    #print(np.array(image))\n",
    "    ax.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/Coding/projects/BOGOMOL-CV/venv/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform_train = v2.Compose([\n",
    "    #v2.Resize((224, 224)),\n",
    "    v2.RandomCrop(32, padding=4),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandAugment(num_ops=2, magnitude=9),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(\n",
    "        #mean=[0.4914, 0.4822, 0.4465],\n",
    "        #std=[0.2470, 0.2435, 0.2616]\n",
    "        mean=[0.507, 0.487, 0.441],\n",
    "        std=[0.267, 0.256, 0.276]\n",
    "    )\n",
    "])\n",
    "\n",
    "transform_val = v2.Compose([\n",
    "    #v2.Resize((224, 224)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(\n",
    "        #mean=[0.4914, 0.4822, 0.4465],\n",
    "        #std=[0.2470, 0.2435, 0.2616]\n",
    "        mean=[0.507, 0.487, 0.441],\n",
    "        std=[0.267, 0.256, 0.276]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10Dataset(Dataset):\n",
    "    def __init__(self, dataset : Dataset, transformation = None):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.transformation = transformation\n",
    "\n",
    "    def get_labeled(self, index : int):\n",
    "        image, label = self.__getitem__(index)\n",
    "        class_name = self.class_names[label]\n",
    "        return image, class_name\n",
    "\n",
    "    def __getitem__(self, index : int):\n",
    "        sample = self.dataset[index]\n",
    "        image = sample['image']\n",
    "        if self.transformation is not None:\n",
    "            image = self.transformation(image)\n",
    "        label = sample['label']\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train_ds = Cifar10Dataset(cifar_train, transform_train)\n",
    "cifar_val_ds = Cifar10Dataset(cifar_val, transform_val)\n",
    "cifar_test_ds = Cifar10Dataset(cifar_test, transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8988765..2.0253625].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7b69e809b650>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cifar_val_ds[2][0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating simple dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutmix = v2.CutMix(alpha=1.0, num_classes=len(class_names))\n",
    "mixup = v2.MixUp(alpha=0.2, num_classes=len(class_names))\n",
    "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image, label in batch:\n",
    "        image = torch.Tensor(image)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    images = torch.stack(images, dim=0).float()\n",
    "    labels = torch.Tensor(labels).long()\n",
    "    return images, labels\n",
    "\n",
    "def collate_fn_train(batch):\n",
    "    return cutmix_or_mixup(collate_fn(batch))\n",
    "\n",
    "cifar_train_dataloader = DataLoader(cifar_train_ds, collate_fn=collate_fn_train, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=8)\n",
    "cifar_val_dataloader = DataLoader(cifar_val_ds, collate_fn=collate_fn, batch_size=BATCH_SIZE, pin_memory=True, num_workers=4)\n",
    "cifar_test_dataloader = DataLoader(cifar_test_ds, collate_fn=collate_fn, batch_size=BATCH_SIZE, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_val = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_fn(pred, soft_targets):\n",
    "    soft_targets = soft_targets.clamp(min=1e-7)\n",
    "    soft_targets = soft_targets / soft_targets.sum(dim=1, keepdim=True)\n",
    "    log_probs = nn.functional.log_softmax(pred, dim=1)\n",
    "    return -(soft_targets * log_probs).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying Image Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "hidden_dim = 128\n",
    "entities = 64\n",
    "\n",
    "model = ImageClassifier(3, hidden_dim, len(class_names), entities, 3, 5).to(device)\n",
    "torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bogomol-61.7M(128, 64)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         GroupNorm-1            [-1, 3, 32, 32]               6\n",
      "            Conv2d-2           [-1, 64, 32, 32]           9,472\n",
      "              GELU-3           [-1, 64, 32, 32]               0\n",
      "            Linear-4              [-1, 81, 128]         524,416\n",
      "              GELU-5              [-1, 81, 128]               0\n",
      "         LayerNorm-6              [-1, 81, 128]             256\n",
      "            Linear-7              [-1, 81, 128]             384\n",
      "              Tanh-8              [-1, 81, 128]               0\n",
      "MultiheadAttention-9  [[-1, 81, 128], [-1, 81, 81]]               0\n",
      "             GELU-10              [-1, 81, 128]               0\n",
      "           Linear-11               [-1, 81, 49]           6,321\n",
      "             Tanh-12               [-1, 81, 49]               0\n",
      "           Linear-13             [-1, 81, 3136]         404,544\n",
      "             GELU-14             [-1, 81, 3136]               0\n",
      "AdaptiveAvgPool2d-15             [-1, 64, 1, 1]               0\n",
      "           Conv2d-16             [-1, 16, 1, 1]           1,040\n",
      "             ReLU-17             [-1, 16, 1, 1]               0\n",
      "           Conv2d-18             [-1, 64, 1, 1]           1,088\n",
      "          Sigmoid-19             [-1, 64, 1, 1]               0\n",
      "               SE-20           [-1, 64, 32, 32]               0\n",
      "          Bogomol-21           [-1, 64, 32, 32]               0\n",
      "        GroupNorm-22           [-1, 64, 32, 32]             128\n",
      "           Conv2d-23           [-1, 64, 32, 32]         200,768\n",
      "             GELU-24           [-1, 64, 32, 32]               0\n",
      "           Linear-25              [-1, 81, 128]         524,416\n",
      "             GELU-26              [-1, 81, 128]               0\n",
      "        LayerNorm-27              [-1, 81, 128]             256\n",
      "           Linear-28              [-1, 81, 128]             384\n",
      "             Tanh-29              [-1, 81, 128]               0\n",
      "MultiheadAttention-30  [[-1, 81, 128], [-1, 81, 81]]               0\n",
      "             GELU-31              [-1, 81, 128]               0\n",
      "           Linear-32               [-1, 81, 49]           6,321\n",
      "             Tanh-33               [-1, 81, 49]               0\n",
      "           Linear-34             [-1, 81, 3136]         404,544\n",
      "             GELU-35             [-1, 81, 3136]               0\n",
      "AdaptiveAvgPool2d-36             [-1, 64, 1, 1]               0\n",
      "           Conv2d-37             [-1, 16, 1, 1]           1,040\n",
      "             ReLU-38             [-1, 16, 1, 1]               0\n",
      "           Conv2d-39             [-1, 64, 1, 1]           1,088\n",
      "          Sigmoid-40             [-1, 64, 1, 1]               0\n",
      "               SE-41           [-1, 64, 32, 32]               0\n",
      "          Bogomol-42           [-1, 64, 32, 32]               0\n",
      "         DropPath-43           [-1, 64, 32, 32]               0\n",
      "        GroupNorm-44           [-1, 64, 32, 32]             128\n",
      "           Conv2d-45           [-1, 64, 32, 32]         200,768\n",
      "             GELU-46           [-1, 64, 32, 32]               0\n",
      "           Linear-47              [-1, 81, 128]         524,416\n",
      "             GELU-48              [-1, 81, 128]               0\n",
      "        LayerNorm-49              [-1, 81, 128]             256\n",
      "           Linear-50              [-1, 81, 128]             384\n",
      "             Tanh-51              [-1, 81, 128]               0\n",
      "MultiheadAttention-52  [[-1, 81, 128], [-1, 81, 81]]               0\n",
      "             GELU-53              [-1, 81, 128]               0\n",
      "           Linear-54               [-1, 81, 49]           6,321\n",
      "             Tanh-55               [-1, 81, 49]               0\n",
      "           Linear-56             [-1, 81, 3136]         404,544\n",
      "             GELU-57             [-1, 81, 3136]               0\n",
      "AdaptiveAvgPool2d-58             [-1, 64, 1, 1]               0\n",
      "           Conv2d-59             [-1, 16, 1, 1]           1,040\n",
      "             ReLU-60             [-1, 16, 1, 1]               0\n",
      "           Conv2d-61             [-1, 64, 1, 1]           1,088\n",
      "          Sigmoid-62             [-1, 64, 1, 1]               0\n",
      "               SE-63           [-1, 64, 32, 32]               0\n",
      "          Bogomol-64           [-1, 64, 32, 32]               0\n",
      "         DropPath-65           [-1, 64, 32, 32]               0\n",
      "        GroupNorm-66           [-1, 64, 32, 32]             128\n",
      "           Conv2d-67           [-1, 64, 32, 32]         200,768\n",
      "             GELU-68           [-1, 64, 32, 32]               0\n",
      "           Linear-69              [-1, 81, 128]         524,416\n",
      "             GELU-70              [-1, 81, 128]               0\n",
      "        LayerNorm-71              [-1, 81, 128]             256\n",
      "           Linear-72              [-1, 81, 128]             384\n",
      "             Tanh-73              [-1, 81, 128]               0\n",
      "MultiheadAttention-74  [[-1, 81, 128], [-1, 81, 81]]               0\n",
      "             GELU-75              [-1, 81, 128]               0\n",
      "           Linear-76               [-1, 81, 49]           6,321\n",
      "             Tanh-77               [-1, 81, 49]               0\n",
      "           Linear-78             [-1, 81, 3136]         404,544\n",
      "             GELU-79             [-1, 81, 3136]               0\n",
      "AdaptiveAvgPool2d-80             [-1, 64, 1, 1]               0\n",
      "           Conv2d-81             [-1, 16, 1, 1]           1,040\n",
      "             ReLU-82             [-1, 16, 1, 1]               0\n",
      "           Conv2d-83             [-1, 64, 1, 1]           1,088\n",
      "          Sigmoid-84             [-1, 64, 1, 1]               0\n",
      "               SE-85           [-1, 64, 32, 32]               0\n",
      "          Bogomol-86           [-1, 64, 32, 32]               0\n",
      "         DropPath-87           [-1, 64, 32, 32]               0\n",
      "        GroupNorm-88           [-1, 64, 32, 32]             128\n",
      "           Conv2d-89           [-1, 64, 32, 32]         200,768\n",
      "             GELU-90           [-1, 64, 32, 32]               0\n",
      "           Linear-91              [-1, 81, 128]         524,416\n",
      "             GELU-92              [-1, 81, 128]               0\n",
      "        LayerNorm-93              [-1, 81, 128]             256\n",
      "           Linear-94              [-1, 81, 128]             384\n",
      "             Tanh-95              [-1, 81, 128]               0\n",
      "MultiheadAttention-96  [[-1, 81, 128], [-1, 81, 81]]               0\n",
      "             GELU-97              [-1, 81, 128]               0\n",
      "           Linear-98               [-1, 81, 49]           6,321\n",
      "             Tanh-99               [-1, 81, 49]               0\n",
      "          Linear-100             [-1, 81, 3136]         404,544\n",
      "            GELU-101             [-1, 81, 3136]               0\n",
      "AdaptiveAvgPool2d-102             [-1, 64, 1, 1]               0\n",
      "          Conv2d-103             [-1, 16, 1, 1]           1,040\n",
      "            ReLU-104             [-1, 16, 1, 1]               0\n",
      "          Conv2d-105             [-1, 64, 1, 1]           1,088\n",
      "         Sigmoid-106             [-1, 64, 1, 1]               0\n",
      "              SE-107           [-1, 64, 32, 32]               0\n",
      "         Bogomol-108           [-1, 64, 32, 32]               0\n",
      "        DropPath-109           [-1, 64, 32, 32]               0\n",
      "       GroupNorm-110           [-1, 64, 32, 32]             128\n",
      "          Conv2d-111           [-1, 64, 32, 32]         200,768\n",
      "            GELU-112           [-1, 64, 32, 32]               0\n",
      "          Linear-113              [-1, 81, 128]         524,416\n",
      "            GELU-114              [-1, 81, 128]               0\n",
      "       LayerNorm-115              [-1, 81, 128]             256\n",
      "          Linear-116              [-1, 81, 128]             384\n",
      "            Tanh-117              [-1, 81, 128]               0\n",
      "MultiheadAttention-118  [[-1, 81, 128], [-1, 81, 81]]               0\n",
      "            GELU-119              [-1, 81, 128]               0\n",
      "          Linear-120               [-1, 81, 49]           6,321\n",
      "            Tanh-121               [-1, 81, 49]               0\n",
      "          Linear-122             [-1, 81, 3136]         404,544\n",
      "            GELU-123             [-1, 81, 3136]               0\n",
      "AdaptiveAvgPool2d-124             [-1, 64, 1, 1]               0\n",
      "          Conv2d-125             [-1, 16, 1, 1]           1,040\n",
      "            ReLU-126             [-1, 16, 1, 1]               0\n",
      "          Conv2d-127             [-1, 64, 1, 1]           1,088\n",
      "         Sigmoid-128             [-1, 64, 1, 1]               0\n",
      "              SE-129           [-1, 64, 32, 32]               0\n",
      "         Bogomol-130           [-1, 64, 32, 32]               0\n",
      "        DropPath-131           [-1, 64, 32, 32]               0\n",
      "       GroupNorm-132           [-1, 64, 32, 32]             128\n",
      "          Conv2d-133          [-1, 128, 16, 16]           8,320\n",
      "    BogomolBlock-134          [-1, 128, 16, 16]               0\n",
      "       GroupNorm-135          [-1, 128, 16, 16]             256\n",
      "          Conv2d-136          [-1, 128, 16, 16]         802,944\n",
      "            GELU-137          [-1, 128, 16, 16]               0\n",
      "          Linear-138               [-1, 9, 128]       1,048,704\n",
      "            GELU-139               [-1, 9, 128]               0\n",
      "       LayerNorm-140               [-1, 9, 128]             256\n",
      "          Linear-141               [-1, 9, 128]             384\n",
      "            Tanh-142               [-1, 9, 128]               0\n",
      "MultiheadAttention-143  [[-1, 9, 128], [-1, 9, 9]]               0\n",
      "            GELU-144               [-1, 9, 128]               0\n",
      "          Linear-145                [-1, 9, 49]           6,321\n",
      "            Tanh-146                [-1, 9, 49]               0\n",
      "          Linear-147              [-1, 9, 6272]         809,088\n",
      "            GELU-148              [-1, 9, 6272]               0\n",
      "AdaptiveAvgPool2d-149            [-1, 128, 1, 1]               0\n",
      "          Conv2d-150             [-1, 32, 1, 1]           4,128\n",
      "            ReLU-151             [-1, 32, 1, 1]               0\n",
      "          Conv2d-152            [-1, 128, 1, 1]           4,224\n",
      "         Sigmoid-153            [-1, 128, 1, 1]               0\n",
      "              SE-154          [-1, 128, 16, 16]               0\n",
      "         Bogomol-155          [-1, 128, 16, 16]               0\n",
      "        DropPath-156          [-1, 128, 16, 16]               0\n",
      "       GroupNorm-157          [-1, 128, 16, 16]             256\n",
      "          Conv2d-158          [-1, 128, 16, 16]         802,944\n",
      "            GELU-159          [-1, 128, 16, 16]               0\n",
      "          Linear-160               [-1, 9, 128]       1,048,704\n",
      "            GELU-161               [-1, 9, 128]               0\n",
      "       LayerNorm-162               [-1, 9, 128]             256\n",
      "          Linear-163               [-1, 9, 128]             384\n",
      "            Tanh-164               [-1, 9, 128]               0\n",
      "MultiheadAttention-165  [[-1, 9, 128], [-1, 9, 9]]               0\n",
      "            GELU-166               [-1, 9, 128]               0\n",
      "          Linear-167                [-1, 9, 49]           6,321\n",
      "            Tanh-168                [-1, 9, 49]               0\n",
      "          Linear-169              [-1, 9, 6272]         809,088\n",
      "            GELU-170              [-1, 9, 6272]               0\n",
      "AdaptiveAvgPool2d-171            [-1, 128, 1, 1]               0\n",
      "          Conv2d-172             [-1, 32, 1, 1]           4,128\n",
      "            ReLU-173             [-1, 32, 1, 1]               0\n",
      "          Conv2d-174            [-1, 128, 1, 1]           4,224\n",
      "         Sigmoid-175            [-1, 128, 1, 1]               0\n",
      "              SE-176          [-1, 128, 16, 16]               0\n",
      "         Bogomol-177          [-1, 128, 16, 16]               0\n",
      "        DropPath-178          [-1, 128, 16, 16]               0\n",
      "       GroupNorm-179          [-1, 128, 16, 16]             256\n",
      "          Conv2d-180          [-1, 128, 16, 16]         802,944\n",
      "            GELU-181          [-1, 128, 16, 16]               0\n",
      "          Linear-182               [-1, 9, 128]       1,048,704\n",
      "            GELU-183               [-1, 9, 128]               0\n",
      "       LayerNorm-184               [-1, 9, 128]             256\n",
      "          Linear-185               [-1, 9, 128]             384\n",
      "            Tanh-186               [-1, 9, 128]               0\n",
      "MultiheadAttention-187  [[-1, 9, 128], [-1, 9, 9]]               0\n",
      "            GELU-188               [-1, 9, 128]               0\n",
      "          Linear-189                [-1, 9, 49]           6,321\n",
      "            Tanh-190                [-1, 9, 49]               0\n",
      "          Linear-191              [-1, 9, 6272]         809,088\n",
      "            GELU-192              [-1, 9, 6272]               0\n",
      "AdaptiveAvgPool2d-193            [-1, 128, 1, 1]               0\n",
      "          Conv2d-194             [-1, 32, 1, 1]           4,128\n",
      "            ReLU-195             [-1, 32, 1, 1]               0\n",
      "          Conv2d-196            [-1, 128, 1, 1]           4,224\n",
      "         Sigmoid-197            [-1, 128, 1, 1]               0\n",
      "              SE-198          [-1, 128, 16, 16]               0\n",
      "         Bogomol-199          [-1, 128, 16, 16]               0\n",
      "        DropPath-200          [-1, 128, 16, 16]               0\n",
      "       GroupNorm-201          [-1, 128, 16, 16]             256\n",
      "          Conv2d-202          [-1, 128, 16, 16]         802,944\n",
      "            GELU-203          [-1, 128, 16, 16]               0\n",
      "          Linear-204               [-1, 9, 128]       1,048,704\n",
      "            GELU-205               [-1, 9, 128]               0\n",
      "       LayerNorm-206               [-1, 9, 128]             256\n",
      "          Linear-207               [-1, 9, 128]             384\n",
      "            Tanh-208               [-1, 9, 128]               0\n",
      "MultiheadAttention-209  [[-1, 9, 128], [-1, 9, 9]]               0\n",
      "            GELU-210               [-1, 9, 128]               0\n",
      "          Linear-211                [-1, 9, 49]           6,321\n",
      "            Tanh-212                [-1, 9, 49]               0\n",
      "          Linear-213              [-1, 9, 6272]         809,088\n",
      "            GELU-214              [-1, 9, 6272]               0\n",
      "AdaptiveAvgPool2d-215            [-1, 128, 1, 1]               0\n",
      "          Conv2d-216             [-1, 32, 1, 1]           4,128\n",
      "            ReLU-217             [-1, 32, 1, 1]               0\n",
      "          Conv2d-218            [-1, 128, 1, 1]           4,224\n",
      "         Sigmoid-219            [-1, 128, 1, 1]               0\n",
      "              SE-220          [-1, 128, 16, 16]               0\n",
      "         Bogomol-221          [-1, 128, 16, 16]               0\n",
      "        DropPath-222          [-1, 128, 16, 16]               0\n",
      "       GroupNorm-223          [-1, 128, 16, 16]             256\n",
      "          Conv2d-224          [-1, 128, 16, 16]         802,944\n",
      "            GELU-225          [-1, 128, 16, 16]               0\n",
      "          Linear-226               [-1, 9, 128]       1,048,704\n",
      "            GELU-227               [-1, 9, 128]               0\n",
      "       LayerNorm-228               [-1, 9, 128]             256\n",
      "          Linear-229               [-1, 9, 128]             384\n",
      "            Tanh-230               [-1, 9, 128]               0\n",
      "MultiheadAttention-231  [[-1, 9, 128], [-1, 9, 9]]               0\n",
      "            GELU-232               [-1, 9, 128]               0\n",
      "          Linear-233                [-1, 9, 49]           6,321\n",
      "            Tanh-234                [-1, 9, 49]               0\n",
      "          Linear-235              [-1, 9, 6272]         809,088\n",
      "            GELU-236              [-1, 9, 6272]               0\n",
      "AdaptiveAvgPool2d-237            [-1, 128, 1, 1]               0\n",
      "          Conv2d-238             [-1, 32, 1, 1]           4,128\n",
      "            ReLU-239             [-1, 32, 1, 1]               0\n",
      "          Conv2d-240            [-1, 128, 1, 1]           4,224\n",
      "         Sigmoid-241            [-1, 128, 1, 1]               0\n",
      "              SE-242          [-1, 128, 16, 16]               0\n",
      "         Bogomol-243          [-1, 128, 16, 16]               0\n",
      "        DropPath-244          [-1, 128, 16, 16]               0\n",
      "       GroupNorm-245          [-1, 128, 16, 16]             256\n",
      "          Conv2d-246            [-1, 256, 8, 8]          33,024\n",
      "    BogomolBlock-247            [-1, 256, 8, 8]               0\n",
      "       GroupNorm-248            [-1, 256, 8, 8]             512\n",
      "          Conv2d-249            [-1, 256, 8, 8]       3,211,520\n",
      "            GELU-250            [-1, 256, 8, 8]               0\n",
      "          Linear-251               [-1, 1, 128]       2,097,280\n",
      "            GELU-252               [-1, 1, 128]               0\n",
      "       LayerNorm-253               [-1, 1, 128]             256\n",
      "          Linear-254               [-1, 1, 128]             384\n",
      "            Tanh-255               [-1, 1, 128]               0\n",
      "MultiheadAttention-256  [[-1, 1, 128], [-1, 1, 1]]               0\n",
      "            GELU-257               [-1, 1, 128]               0\n",
      "          Linear-258                [-1, 1, 49]           6,321\n",
      "            Tanh-259                [-1, 1, 49]               0\n",
      "          Linear-260             [-1, 1, 12544]       1,618,176\n",
      "            GELU-261             [-1, 1, 12544]               0\n",
      "AdaptiveAvgPool2d-262            [-1, 256, 1, 1]               0\n",
      "          Conv2d-263             [-1, 64, 1, 1]          16,448\n",
      "            ReLU-264             [-1, 64, 1, 1]               0\n",
      "          Conv2d-265            [-1, 256, 1, 1]          16,640\n",
      "         Sigmoid-266            [-1, 256, 1, 1]               0\n",
      "              SE-267            [-1, 256, 8, 8]               0\n",
      "         Bogomol-268            [-1, 256, 8, 8]               0\n",
      "        DropPath-269            [-1, 256, 8, 8]               0\n",
      "       GroupNorm-270            [-1, 256, 8, 8]             512\n",
      "          Conv2d-271            [-1, 256, 8, 8]       3,211,520\n",
      "            GELU-272            [-1, 256, 8, 8]               0\n",
      "          Linear-273               [-1, 1, 128]       2,097,280\n",
      "            GELU-274               [-1, 1, 128]               0\n",
      "       LayerNorm-275               [-1, 1, 128]             256\n",
      "          Linear-276               [-1, 1, 128]             384\n",
      "            Tanh-277               [-1, 1, 128]               0\n",
      "MultiheadAttention-278  [[-1, 1, 128], [-1, 1, 1]]               0\n",
      "            GELU-279               [-1, 1, 128]               0\n",
      "          Linear-280                [-1, 1, 49]           6,321\n",
      "            Tanh-281                [-1, 1, 49]               0\n",
      "          Linear-282             [-1, 1, 12544]       1,618,176\n",
      "            GELU-283             [-1, 1, 12544]               0\n",
      "AdaptiveAvgPool2d-284            [-1, 256, 1, 1]               0\n",
      "          Conv2d-285             [-1, 64, 1, 1]          16,448\n",
      "            ReLU-286             [-1, 64, 1, 1]               0\n",
      "          Conv2d-287            [-1, 256, 1, 1]          16,640\n",
      "         Sigmoid-288            [-1, 256, 1, 1]               0\n",
      "              SE-289            [-1, 256, 8, 8]               0\n",
      "         Bogomol-290            [-1, 256, 8, 8]               0\n",
      "        DropPath-291            [-1, 256, 8, 8]               0\n",
      "       GroupNorm-292            [-1, 256, 8, 8]             512\n",
      "          Conv2d-293            [-1, 256, 8, 8]       3,211,520\n",
      "            GELU-294            [-1, 256, 8, 8]               0\n",
      "          Linear-295               [-1, 1, 128]       2,097,280\n",
      "            GELU-296               [-1, 1, 128]               0\n",
      "       LayerNorm-297               [-1, 1, 128]             256\n",
      "          Linear-298               [-1, 1, 128]             384\n",
      "            Tanh-299               [-1, 1, 128]               0\n",
      "MultiheadAttention-300  [[-1, 1, 128], [-1, 1, 1]]               0\n",
      "            GELU-301               [-1, 1, 128]               0\n",
      "          Linear-302                [-1, 1, 49]           6,321\n",
      "            Tanh-303                [-1, 1, 49]               0\n",
      "          Linear-304             [-1, 1, 12544]       1,618,176\n",
      "            GELU-305             [-1, 1, 12544]               0\n",
      "AdaptiveAvgPool2d-306            [-1, 256, 1, 1]               0\n",
      "          Conv2d-307             [-1, 64, 1, 1]          16,448\n",
      "            ReLU-308             [-1, 64, 1, 1]               0\n",
      "          Conv2d-309            [-1, 256, 1, 1]          16,640\n",
      "         Sigmoid-310            [-1, 256, 1, 1]               0\n",
      "              SE-311            [-1, 256, 8, 8]               0\n",
      "         Bogomol-312            [-1, 256, 8, 8]               0\n",
      "        DropPath-313            [-1, 256, 8, 8]               0\n",
      "       GroupNorm-314            [-1, 256, 8, 8]             512\n",
      "          Conv2d-315            [-1, 256, 8, 8]       3,211,520\n",
      "            GELU-316            [-1, 256, 8, 8]               0\n",
      "          Linear-317               [-1, 1, 128]       2,097,280\n",
      "            GELU-318               [-1, 1, 128]               0\n",
      "       LayerNorm-319               [-1, 1, 128]             256\n",
      "          Linear-320               [-1, 1, 128]             384\n",
      "            Tanh-321               [-1, 1, 128]               0\n",
      "MultiheadAttention-322  [[-1, 1, 128], [-1, 1, 1]]               0\n",
      "            GELU-323               [-1, 1, 128]               0\n",
      "          Linear-324                [-1, 1, 49]           6,321\n",
      "            Tanh-325                [-1, 1, 49]               0\n",
      "          Linear-326             [-1, 1, 12544]       1,618,176\n",
      "            GELU-327             [-1, 1, 12544]               0\n",
      "AdaptiveAvgPool2d-328            [-1, 256, 1, 1]               0\n",
      "          Conv2d-329             [-1, 64, 1, 1]          16,448\n",
      "            ReLU-330             [-1, 64, 1, 1]               0\n",
      "          Conv2d-331            [-1, 256, 1, 1]          16,640\n",
      "         Sigmoid-332            [-1, 256, 1, 1]               0\n",
      "              SE-333            [-1, 256, 8, 8]               0\n",
      "         Bogomol-334            [-1, 256, 8, 8]               0\n",
      "        DropPath-335            [-1, 256, 8, 8]               0\n",
      "       GroupNorm-336            [-1, 256, 8, 8]             512\n",
      "          Conv2d-337            [-1, 256, 8, 8]       3,211,520\n",
      "            GELU-338            [-1, 256, 8, 8]               0\n",
      "          Linear-339               [-1, 1, 128]       2,097,280\n",
      "            GELU-340               [-1, 1, 128]               0\n",
      "       LayerNorm-341               [-1, 1, 128]             256\n",
      "          Linear-342               [-1, 1, 128]             384\n",
      "            Tanh-343               [-1, 1, 128]               0\n",
      "MultiheadAttention-344  [[-1, 1, 128], [-1, 1, 1]]               0\n",
      "            GELU-345               [-1, 1, 128]               0\n",
      "          Linear-346                [-1, 1, 49]           6,321\n",
      "            Tanh-347                [-1, 1, 49]               0\n",
      "          Linear-348             [-1, 1, 12544]       1,618,176\n",
      "            GELU-349             [-1, 1, 12544]               0\n",
      "AdaptiveAvgPool2d-350            [-1, 256, 1, 1]               0\n",
      "          Conv2d-351             [-1, 64, 1, 1]          16,448\n",
      "            ReLU-352             [-1, 64, 1, 1]               0\n",
      "          Conv2d-353            [-1, 256, 1, 1]          16,640\n",
      "         Sigmoid-354            [-1, 256, 1, 1]               0\n",
      "              SE-355            [-1, 256, 8, 8]               0\n",
      "         Bogomol-356            [-1, 256, 8, 8]               0\n",
      "        DropPath-357            [-1, 256, 8, 8]               0\n",
      "       GroupNorm-358            [-1, 256, 8, 8]             512\n",
      "          Conv2d-359            [-1, 512, 4, 4]         131,584\n",
      "    BogomolBlock-360            [-1, 512, 4, 4]               0\n",
      "         Flatten-361                 [-1, 8192]               0\n",
      "       LayerNorm-362                 [-1, 8192]          16,384\n",
      "          Linear-363                   [-1, 10]          81,930\n",
      "================================================================\n",
      "Total params: 55,133,600\n",
      "Trainable params: 55,133,600\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3055.21\n",
      "Params size (MB): 210.32\n",
      "Estimated Total Size (MB): 3265.54\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "model_name = f\"bogomol-{num_parameters/1e+6:.1f}M({hidden_dim}, {entities})\"\n",
    "\n",
    "print(model_name)\n",
    "summary(model, (3, IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    \"train_loss\" : [float('inf')],\n",
    "    \"train_acc\" : [0],\n",
    "    \"val_loss\" : [float('inf')],\n",
    "    \"val_acc\" : [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions: torch.Tensor, ground_truth: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Вычисляет точность предсказаний модели на CIFAR-10.\n",
    "\n",
    "    Аргументы:\n",
    "        predictions (torch.Tensor): Логиты сети (без softmax), размер [batch_size, num_classes].\n",
    "        ground_truth (torch.Tensor): Истинные метки, размер [batch_size].\n",
    "\n",
    "    Возвращает:\n",
    "        float: Значение точности (accuracy) в процентах.\n",
    "    \"\"\"\n",
    "    predicted_classes = predictions.argmax(dim=1)\n",
    "    correct = (predicted_classes == ground_truth).sum().item()\n",
    "    accuracy = correct / ground_truth.size(0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, scheduler, scaler, accumulation_steps : int = 4):\n",
    "    model.train()\n",
    "    pbar = tqdm(dataloader, f\"Train loss: {history['train_loss'][-1]:.3f}, acc: {history['train_acc'][-1]:.3f}\")\n",
    "    total_loss = 0\n",
    "    cur_acc = 0\n",
    "    total_acc = 0\n",
    "    out_of_mem = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        try:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.autocast('cuda'):\n",
    "                prediction = model(images)\n",
    "                loss_value = loss_fn(prediction, labels)\n",
    "            total_loss += loss_value.item()\n",
    "\n",
    "            scaler.scale(loss_value/accumulation_steps).backward()\n",
    "\n",
    "            #with torch.no_grad():\n",
    "            #    cur_acc = compute_accuracy(prediction, labels)\n",
    "            #    total_acc += cur_acc\n",
    "\n",
    "            if (batch_idx+1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                pbar.set_description(f\"Train loss: {loss_value.item():.3f}, acc: {cur_acc:.3f}\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "            if 'out of memory' in str(e):\n",
    "                out_of_mem += 1\n",
    "                torch.cuda.empty_cache()\n",
    "            else:\n",
    "                raise e\n",
    "        finally:\n",
    "            scheduler.step()\n",
    "    else:\n",
    "        if (batch_idx+1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "    mean_loss = total_loss/(batch_idx + 1)\n",
    "    history['train_loss'].append(mean_loss)\n",
    "    mean_acc = total_acc/(batch_idx + 1)\n",
    "    history['train_acc'].append(mean_acc)\n",
    "    if out_of_mem:\n",
    "        print(f\"Memory overflow occurred in {out_of_mem}/{batch_idx+1} batches!\")\n",
    "    return mean_loss, mean_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    pbar = tqdm(dataloader, f\"Validation loss: {history['val_loss'][-1]:.3f}\")\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    out_of_mem = 0\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        try:\n",
    "            prediction = model(images)\n",
    "            loss_value = loss_fn_val(prediction, labels)\n",
    "            total_loss += loss_value.item()\n",
    "            cur_acc = compute_accuracy(prediction, labels)\n",
    "            total_acc += cur_acc\n",
    "            if batch_idx % 10 == 0:\n",
    "                pbar.set_description(f\"Validation loss: {loss_value.item():.3f}, acc: {cur_acc:.3f}\")\n",
    "        except RuntimeError as e:\n",
    "\n",
    "            if 'out of memory' in str(e):\n",
    "                out_of_mem += 1\n",
    "                torch.cuda.empty_cache()\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "\n",
    "    mean_loss = total_loss/(batch_idx + 1)\n",
    "    history['val_loss'].append(mean_loss)\n",
    "    mean_acc = total_acc/(batch_idx + 1)\n",
    "    history['val_acc'].append(mean_acc)\n",
    "    if out_of_mem:\n",
    "        print(f\"Memory overflow occurred in {out_of_mem}/{batch_idx+1} batches!\")\n",
    "    return mean_loss, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizer(\n",
    "    model,\n",
    "    base_lr=3e-4,\n",
    "    weight_decay=0.1,\n",
    "    betas=(0.9, 0.999),\n",
    "    warmup_epochs=5,\n",
    "    total_epochs=100,\n",
    "    steps_per_epoch=1000\n",
    "):\n",
    "    # Group parameters\n",
    "    decay_params, no_decay_params = [], []\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue\n",
    "        if param.ndim == 1 or name.endswith(\".bias\") or \"norm\" in name.lower():\n",
    "            no_decay_params.append(param)\n",
    "        else:\n",
    "            decay_params.append(param)\n",
    "\n",
    "    param_groups = [\n",
    "        {\"params\": decay_params, \"weight_decay\": weight_decay},\n",
    "        {\"params\": no_decay_params, \"weight_decay\": 0.0},\n",
    "    ]\n",
    "\n",
    "    # AdamW optimizer\n",
    "    optimizer = AdamW(param_groups, lr=base_lr, betas=betas)\n",
    "\n",
    "    # Scheduler with linear warmup + cosine decay\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_epochs*steps_per_epoch:\n",
    "            return current_step / max(1, warmup_epochs*steps_per_epoch)\n",
    "        progress = float(current_step - warmup_epochs*steps_per_epoch) / max(1, (total_epochs - warmup_epochs)*steps_per_epoch)\n",
    "        return 0.5 * (1.0 + torch.cos(torch.tensor(progress * torch.pi)))\n",
    "\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "optimizer, scheduler = configure_optimizer(model, base_lr=3e-4, warmup_epochs=EPOCHS//20, total_epochs=EPOCHS, steps_per_epoch=len(cifar_train_dataloader))\n",
    "scaler = torch.GradScaler(device)\n",
    "checkpoint_pth = './models'\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    print(f\"Training epoch: {i+1}/{EPOCHS}\")\n",
    "    train_loss, train_acc = train(model, cifar_train_dataloader, optimizer, scheduler, scaler)\n",
    "    print(f\"Average training loss: {train_loss:.3f}, accuracy: {train_acc:.3f}\")\n",
    "    print(f\"Learning rate: {scheduler.get_last_lr()[0]}, gradient scale: {scaler.get_scale()}\")\n",
    "    val_loss, val_acc = validate(model, cifar_val_dataloader)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_params = model.state_dict()\n",
    "        torch.save(best_params, os.path.join(checkpoint_pth, model_name+'.pth'))\n",
    "    print(f\"Average validation loss: {val_loss:.3f}, accuracy: {val_acc:.3f}\")\n",
    "    print(\"-\"*80)\n",
    "    if train_loss is torch.nan:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model\n",
    "best_model.load_state_dict(torch.load(os.path.join(checkpoint_pth, model_name+'.pth'), weights_only=True))\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_pth = './plots'\n",
    "\n",
    "plt.plot(history['train_loss'], label=\"Train loss\")\n",
    "plt.plot(history['val_loss'], label=\"Validation loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Model loss\")\n",
    "plt.savefig(os.path.join(plots_pth, f'{model_name}-loss.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['train_acc'], label=\"Train accuracy\")\n",
    "plt.plot(history['val_acc'], label=\"Validation accuracy\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Model accuracy\")\n",
    "plt.savefig(os.path.join(plots_pth, f'{model_name}-acc.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = validate(best_model, cifar_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.txt', 'w') as f:\n",
    "    f.write(f\"Train accuracy : {max(history['train_acc'])}, loss : {min(history['train_loss'])}\\n\")\n",
    "    f.write(f\"Validation accuracy : {max(history['val_acc'])}, loss : {min(history['val_loss'])}\\n\")\n",
    "    f.write(f\"Test accuracy : {test_acc}, loss : {test_loss}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
